{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook', font_scale=1.33)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 1],\n",
       "        [1, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 1],\n",
       "        [0, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [0, 1, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 1, 1],\n",
       "        [0, 1, 0]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from laverna.task import simulate_reversal_task\n",
    "\n",
    "simulate_reversal_task([30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Noodling\n",
    "#### 1.1 Exploration on Latent Traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(47404)\n",
    "\n",
    "def inv_logit(arr):\n",
    "    return 1. / (1 + np.exp(-arr))\n",
    "\n",
    "x = np.random.normal(0,1,1000)\n",
    "b = -1\n",
    "a = 1\n",
    "\n",
    "theta = inv_logit( a * (x - b) )\n",
    "\n",
    "sns.distplot(theta, kde=False, bins=np.linspace(0,1,21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Simmy sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import bernoulli, norm, skewnorm\n",
    "np.random.seed(0)\n",
    "\n",
    "## Define metadata.\n",
    "n_agents = 1000\n",
    "n_items = 10\n",
    "\n",
    "## Define simulation parameters.\n",
    "a = 3\n",
    "b = 0.5\n",
    "mu = -1\n",
    "\n",
    "## Simulate values.\n",
    "def inv_logit(arr):\n",
    "    return 1. / (1 + np.exp(-arr))\n",
    "\n",
    "phi = norm(0,1).rvs(n_agents)\n",
    "phi = inv_logit( a * ( phi + b ) )\n",
    "psi = norm(mu,1).rvs(n_agents)\n",
    "\n",
    "## Compute attentive response probabilities.\n",
    "tau = norm(0,1).ppf([0.17,0.50,0.83])\n",
    "theta = norm(0,1).cdf(np.subtract.outer(tau, psi)).T.round(6)\n",
    "theta = np.column_stack([np.zeros(n_agents), theta, np.ones(n_agents)])\n",
    "theta = np.diff(theta)\n",
    "\n",
    "## Simulate responses.\n",
    "Y = np.zeros((n_agents, n_items),dtype=int)\n",
    "\n",
    "for i in range(n_items):\n",
    "    \n",
    "    ## Simulate attentive repsonse.\n",
    "    y_effort = np.apply_along_axis(lambda p: np.random.multinomial(1, p), 1, theta)\n",
    "    y_effort = np.argmax(y_effort, axis=1)\n",
    "    \n",
    "    ## Simulate random response.\n",
    "    y_rand = np.random.randint(0,4,n_agents)\n",
    "    \n",
    "    ## Store response.\n",
    "    w = np.random.binomial(1, phi)\n",
    "    Y[:,i] = np.where(w, y_effort, y_rand)\n",
    "    \n",
    "## Compute sum scores.\n",
    "scores = Y.sum(axis=1) / (3 * n_items)\n",
    "\n",
    "## Initialize canvas.\n",
    "fig, axes = plt.subplots(1,3,figsize=(15,4))\n",
    "\n",
    "## Plot distribution of effortful responding.\n",
    "sns.distplot(phi, kde=False, bins=np.linspace(0,1,11), ax=axes[0])\n",
    "axes[0].set(xlabel='Trait Effort')\n",
    "\n",
    "## Plot response likelihood.\n",
    "axes[1].bar(np.arange(4), np.average(theta, axis=0, weights=phi))\n",
    "axes[1].set(xticks=np.arange(4), )\n",
    "\n",
    "## Plot distribution of sum scores.\n",
    "sns.scatterplot(phi, scores, size=3, legend=False, ax=axes[2])\n",
    "axes[2].set(xlabel='Trait Effort', ylabel='Sum Score')\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section XX: WSLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(47404)\n",
    "\n",
    "def softmax(arr):\n",
    "    \"\"\"Scale-robust softmax choice rule.\"\"\"\n",
    "    arr = np.exp(arr - np.max(arr))\n",
    "    return arr / arr.sum()\n",
    "\n",
    "## Define metadata.\n",
    "n_agents = 1000\n",
    "n_trials = 90\n",
    "n_arms = 3\n",
    "epsilon = 0.05\n",
    "\n",
    "## Simulate probabilities.\n",
    "P = np.zeros((n_agents,n_arms))\n",
    "P[np.arange(n_agents), np.argmax(np.random.normal(size=P.shape), axis=1)] = 1\n",
    "P = np.where(P, 0.8, 0.2)\n",
    "\n",
    "## Simulate rewards.\n",
    "R = np.zeros((n_trials, n_agents, n_arms))\n",
    "Q = np.zeros_like(R)\n",
    "\n",
    "for i in range(n_trials):\n",
    "    if not i % 15: P = np.apply_along_axis(np.roll, 1, P, np.random.choice([1,-1],1))\n",
    "    Q[i] = P.copy()\n",
    "    R[i] = np.random.binomial(1,P)\n",
    "Q = np.argmax(Q, axis=-1)\n",
    "    \n",
    "    \n",
    "## Simulate choice.\n",
    "Y = np.zeros((n_trials,n_agents),dtype=int)\n",
    "Y[0] = np.random.randint(0,3,(n_agents))\n",
    "\n",
    "ix = np.arange(n_agents)\n",
    "\n",
    "for i in range(1, n_trials):\n",
    "    \n",
    "    ## Prepopulate choice.\n",
    "    p = np.zeros((n_agents,3))\n",
    "    p[ix, Y[i-1]] = 1\n",
    "    \n",
    "    ## Observe previous outcome.\n",
    "    r = R[i-1,ix,Y[i-1]]\n",
    "    \n",
    "    ## Update probabilities.\n",
    "    p = np.abs(p.T - (1-r))\n",
    "    p = (p / p.sum(axis=0)).T\n",
    "    \n",
    "    ## Add exploration.\n",
    "    p = (1-epsilon) * p + (epsilon / 3)\n",
    "    \n",
    "    ## Simulate choice.\n",
    "    f = lambda x: np.random.multinomial(1, x)\n",
    "    Y[i] = np.argmax(np.apply_along_axis(f, 1, p), axis=1)\n",
    "    \n",
    "sns.distplot((Y == Q).mean(axis=0), bins=np.linspace(0.3,1,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# haha fuck you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = R.sum(axis=1).argmax(axis=1)\n",
    "\n",
    "[np.mean(y==t) for y, t in zip(Y,target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
